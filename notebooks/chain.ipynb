{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup requirements\n",
    "%pip install -r ./../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openai_api_key from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "model=\"gpt-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of langchain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy-paste Medienmitteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste a media release as 'text_input_medienmitteilung'\n",
    "text_input_medienmitteilung = \"\"\"\n",
    "\n",
    "    # Medienmitteilung\n",
    "\n",
    "    ## Horizon-Paket: Bund finanziert weitere Übergangsmassnahmen für Einzelprojekte\n",
    "    \n",
    "    Bern, 25.10.2023 - Der Bund stellt für die Starting und Consolidator Grants 2024 des Europäischen Forschungsrates (European Research Council, ERC) Mittel für Übergangsmassnahmen zur Verfügung. Dies hat der Bundesrat am 25. Oktober 2023 beschlossen. Aufgrund der aktuellen Nicht-Assoziierung am Horizon-Paket sind Forschende in der Schweiz zu den entsprechenden europäischen Ausschreibungen nicht zugelassen.\n",
    "\n",
    "    Die Grants des Europäischen Forschungsrates fördern exzellente Grundlagenforschung und sind ein zentrales Förderinstrument für Spitzenforschende in der Schweiz. Diese waren bei vergangenen Ausschreibungen im internationalen Vergleich überdurchschnittlich erfolgreich. Daher soll Forschenden in der Schweiz, wie bereits in den Vorjahren, ein adäquater nationaler Ersatz angeboten werden. Der Bundesrat stellt dafür maximal 84 Millionen Franken zur Verfügung. Dafür werden Mittel eingesetzt, die das Parlament Ende 2020 für die Teilnahme der Schweiz am Horizon-Paket gesprochen hatte. Das Staatssekretariat für Bildung, Forschung und Innovation (SBFI) wird den Schweizerischen Nationalfonds mit den Ausschreibungen «SNSF Starting Grants 2024» und gegebenenfalls «SNSF Consolidator Grants 2024» beauftragen.\n",
    "\n",
    "    Der Bundesrat verfolgt weiterhin das Ziel einer raschestmöglichen Assoziierung der Schweiz am Horizon-Paket. Die Ausschreibungen 2024 für die europäischen Stipendien (ERC Starting Grants, ERC Consolidator Grants) schliessen jedoch bereits im Oktober bzw. Dezember 2023. Daher sind sie den Forschenden in der Schweiz auch im Falle einer Assoziierung im Jahr 2024 nicht zugänglich.\n",
    "\n",
    "    Horizon Europe\n",
    "\n",
    "    Horizon Europe, das neunte EU-Rahmenprogramm für Forschung und Innovation, läuft von 2021 bis 2027 und ist mit einem Budget von gut 95 Milliarden Euro das weltweit grösste Forschungs- und Innovationsförderprogramm. Die Schweiz war am Vorgängerprogramm, Horizon 2020, assoziiert. Der Bundesrat strebt raschestmöglich den gleichen Status für Horizon Europe und damit verbundene Programme und Initiativen an (Euratom-Programm, ITER und Digital Europe Programme). Der Bundesrat hat für die Ausschreibungen 2021, 2022 und 2023 bereits Übergangsmassnahmen in der Höhe von 1,85 Milliarden Schweizer Franken zur Verfügung gestellt.\n",
    "\n",
    "    Adresse für Rückfragen\n",
    "\n",
    "    Kommunikationsdienst GS-WBF\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run this ai-machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "important facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_facts: Analyze the following text and identify all important facts\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Analyze the following text and \n",
    "    identify all important facts.  \n",
    "    The text is from news.admin.ch and is an \n",
    "    official media release: \\n {medienmitteilung}\\n\\n\n",
    "    rule: answer in same language as the media release!\n",
    "    Your fact analysis:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_facts = runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung})\n",
    "print(result_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2:\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_top10keywords: Identify 10 keywords from the facts\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Identify 10 keywords that are likely to rank well \n",
    "    on Google (Switzerland). \n",
    "    The keywords are in the same language as the \n",
    "    following text and start with a #.\n",
    "\n",
    "    Text: \n",
    "    {facts}\n",
    "    \n",
    "    Examples: #FederalCouncil #Geneva #Nyon #Motorway #A1 #Traffic #Trafficflow #Motorway     \n",
    "    Your keywords incl. #:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_top10keywords = runnable.invoke({\"facts\": result_facts})\n",
    "print(result_top10keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_top3keywords: Analyze the following keywords and text. \n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Analyze the following keywords and text. \n",
    "    Identify exactly 3 keywords that can rank \n",
    "    well on Google (Switzerland). \n",
    "\n",
    "    Examples: #FederalCouncil #ChuckNorris #Thailand  (on one line)\n",
    "   \n",
    "    ===============\n",
    "    Keywords: \n",
    "    {top10keywords}\n",
    "\n",
    "    Text: \n",
    "    {medienmitteilung}\n",
    "    ===============\n",
    "    Your top 3 keywords in the same language as the text/keywords:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_top3keywords = runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung, \"top10keywords\": result_top10keywords})\n",
    "print(result_top3keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3:\n",
    "social media content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_tweets: write 3 matching tweets for a specific media release, facts, keywords.\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a neutral media spokesperson for the Federal Council \n",
    "    and write 3 matching tweets for a specific media release.\n",
    "    \n",
    "    Your tweets always contain:\n",
    "    1. the 2 most important facts\n",
    "    2. the 3 most important keywords\n",
    "    3. 4 matching emojis.\n",
    "    4. the tweet ends with the string [url].\n",
    "\n",
    "    Rules:\n",
    "    You answer in the same language as the media release.\n",
    "\n",
    "    Sources: \n",
    "    ===========\n",
    "    Facts: {facts}\n",
    "    Top-Keywords: {top3keywords}\n",
    "    Media release: {medienmitteilung}\n",
    "    ==============\n",
    "    Your 3 different tweet suggestions:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_tweets = runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung, \"top3keywords\": result_top3keywords, \"facts\": result_facts})\n",
    "print(result_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4:\n",
    "prepare for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_fragen_20min: from 20min.ch/Wagenknecht and will collect 3 critical questions. \n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a reporter (male) for 20min.ch and \n",
    "    will collect 10 critical questions. \n",
    "    At the end we need the 3 most critical \n",
    "    questions.\n",
    "\n",
    "    You think like Sahra Wagenknecht. \n",
    "\n",
    "    It is important that the questions \n",
    "    directly to the press release.\n",
    "    \n",
    "    Important:\n",
    "    The questions are critical but not offensive. \n",
    "    and refer to the media release, the facts and a top keyword.\n",
    "\n",
    "    Rules:\n",
    "    Answer in the same language as the media release.\n",
    "\n",
    "    Sources: \n",
    "    ===========\n",
    "    Facts: {facts}\n",
    "    Top-Keywords: {top3keywords}\n",
    "    Media release: {medienmitteilung}\n",
    "    ==============\n",
    "    Your top-3 moust critical questions:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_fragen_20min = runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung, \"top3keywords\": result_top3keywords, \"facts\": result_facts})\n",
    "print(result_fragen_20min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_fragen_NZZ: from NZZ/Donald Duck and will collect 3 critical questions. \n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a reporter (female) for the NZZ and will \n",
    "    collect 10 critical questions. \n",
    "    At the end we need the 3 most critical \n",
    "    questions.\n",
    "\n",
    "    You think like Donald Duck.\n",
    "\n",
    "    It is important that the questions \n",
    "    relate directly to the press release.\n",
    "    \n",
    "    This is important:\n",
    "    The questions are critical, but not insulting. \n",
    "    And refer to the press release, the facts and a keyword.\n",
    "\n",
    "    Rules:\n",
    "    Answer in the same language as in the press release.\n",
    "\n",
    "    Sources: \n",
    "    ===========\n",
    "    Facts {facts}\n",
    "    Keywords: {top3keywords}\n",
    "    Media Release: {medienmitteilung}\n",
    "    ==============\n",
    "    Your top 3 most critical questions:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_fragen_nzz = runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung, \"top3keywords\": result_top3keywords, \"facts\": result_facts})\n",
    "print(result_fragen_nzz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5:\n",
    "explain to a child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_zusammenfassung_kind: summary for a 10 year old child \n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Create a summary of the following text \n",
    "    for a 10 year old child of a media release.\n",
    "\n",
    "    Important rule:\n",
    "    Answer in the same language as the media release!\n",
    "\n",
    "    Sources: \n",
    "    ===========\n",
    "    Facts: {facts}\n",
    "    Media release: {medienmitteilung}\n",
    "    ==============\n",
    "    Your child-friendly summary in correct language:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_zusammenfassung_kind =  runnable.invoke({\"medienmitteilung\": text_input_medienmitteilung, \"facts\": result_facts})\n",
    "print(result_zusammenfassung_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 6:\n",
    "illustrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dalle3prompt: DALL-E prompt : black and white comic book panel in style of asterix & obelix in mid-21th \n",
    "# copy-paste the result_dalle3prompt into a good image generator like Midjourney or DallE-3 \n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Create a prompt to generate \n",
    "    with DALL-E a matching image.\n",
    "    the prompt must be child-friendly.\n",
    "\n",
    "    Important Roules:\n",
    "    =================\n",
    "    1) Your DALL-E Prompt must be in english.\n",
    "    2) It must include the following texts:\n",
    "        A)\"create a black and white comic book panel\"\n",
    "        B)\"comic illustration reminiscent of European adventure comics of the mid-21th century\"\n",
    "        C)\"in a informative way.\" \n",
    "        D) [SCENE]\n",
    "        E) The scene plays in switzerland.\n",
    "        F) Prompt must be length 1000 or less.\n",
    "    3) \"Include a dramatic sound effect text saying &quot;{top3keywords}&quot;\n",
    "    =================\n",
    "\n",
    "    Contextinformation for the [SCENE]: {zusammenfassung_kind}\n",
    "    ==============\n",
    "    Generated the [SCENE] and following the rules 1-3!\n",
    "    ==============\n",
    "    Your DALL-E Prompt follows rules 1-3:\n",
    "\"\"\")\n",
    "runnable = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "result_dalle3prompt =  runnable.invoke({\"zusammenfassung_kind\": result_zusammenfassung_kind, \"top3keywords\": result_top3keywords, \"facts\": result_facts})\n",
    "print(result_dalle3prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to a DELL-E 2 image (Midjourney or DallE-3 are much better!)\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"image_desc\"],\n",
    "    template=\"{image_desc}\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "image_url = DallEAPIWrapper().run(chain.run(result_dalle3prompt))\n",
    "image_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
